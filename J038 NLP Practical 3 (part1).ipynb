{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9291509,
          "sourceType": "datasetVersion",
          "datasetId": 5624978
        },
        {
          "sourceId": 9292186,
          "sourceType": "datasetVersion",
          "datasetId": 5625457
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "J038 ASST 3 PART 1",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'glove-6b:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5624978%2F9291509%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240901%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240901T083220Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da4b2be8990b8c605aa299392f6c0627c7c3b450d92714c7e6f71dc1e7cee28bb3275f6366e7f572b9e552ab63d419aebc0ff0262e9b2bf581994d4175bc83cc78affd214742e0c9b25fdd7c17c6f2402e31c74d7fd777f34f4efb99e8ec742e33da58e39ad843ac09f77372278396978ca543f02d48187c92e9c69774ee01956eb51473b1edfdd3fa81d2f4ba207c34e67e5650139ead97470b954e580f2b53264114145ebf0f624241c4d389a793d97dcc4a57c2ee2358f9af7d3b8fdcc4afb4b1037cb79e28b47df70c94bbcb13b01db8e2b8b01da96808598e2e915e0f0a804d41cc74f9150b6e68250383918ec341ad39f2b8023301df9bdb7f4f4209bf4,imdbdataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5625457%2F9292186%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240901%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240901T083220Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dc5750c32bb54cd3b9eb1a708c3081258d0789aee56a69b2d5a6f0794a630eff09ca86784b21c01de7dd513137ab3cb528d39c35f92118907ba5bb058ff362d0919237ee0386881e88dcbbb041cd5af70dfb435aafd9a9c791a2df6fee22ae1ad47579bb0718d13c499fb8049061876e8eadf1ab391c834a5c28989a0fa75fd1a1a5e4e09d4257a7960e872ff8e4928235db65b09cbb504e0f32ffe65e29eafb0fbbaa75ccd7c6a644055f0cfe5d3faca0b30d9b39ddf63bfd42767cb2d8bd2db416078b709edb615b0783e374c105c20042ae99da6f43b0a9dcaa84c94cf06e9930d77b2841dc36a0551e8030c2fca2b9ad655a510dcb6ff6490cfccc8626a99'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "lcHVHhb5trpK"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ygbg-yK9trpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages if not already installed\n",
        "# !pip install torch torchvision torchtext pandas numpy scikit-learn nltk\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:12:01.555056Z",
          "iopub.execute_input": "2024-09-01T08:12:01.555632Z",
          "iopub.status.idle": "2024-09-01T08:12:06.552559Z",
          "shell.execute_reply.started": "2024-09-01T08:12:01.555594Z",
          "shell.execute_reply": "2024-09-01T08:12:06.551652Z"
        },
        "trusted": true,
        "id": "3aCNUWzZtrpO",
        "outputId": "f4eefada-f2ac-40f7-d8a9-66f342f7c7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the dataset is downloaded and available locally\n",
        "df = pd.read_csv('/kaggle/input/imdbdataset/IMDB Dataset.csv')\n",
        "df.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:12:55.254559Z",
          "iopub.execute_input": "2024-09-01T08:12:55.255225Z",
          "iopub.status.idle": "2024-09-01T08:12:56.580253Z",
          "shell.execute_reply.started": "2024-09-01T08:12:55.255184Z",
          "shell.execute_reply": "2024-09-01T08:12:56.579351Z"
        },
        "trusted": true,
        "id": "nCtKC8U_trpO",
        "outputId": "838db56d-eae3-4f10-b863-bfc5744b096d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing\n",
        "df['clean_review'] = df['review'].progress_apply(preprocess_text)\n",
        "df.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:13:25.322909Z",
          "iopub.execute_input": "2024-09-01T08:13:25.323362Z",
          "iopub.status.idle": "2024-09-01T08:14:55.523837Z",
          "shell.execute_reply.started": "2024-09-01T08:13:25.323306Z",
          "shell.execute_reply": "2024-09-01T08:14:55.52275Z"
        },
        "trusted": true,
        "id": "tybcAaTwtrpP",
        "outputId": "f3f6e906-4465-4fcd-fe4f-885abca7dd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 50000/50000 [01:30<00:00, 554.49it/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              review sentiment  \\\n0  One of the other reviewers has mentioned that ...  positive   \n1  A wonderful little production. <br /><br />The...  positive   \n2  I thought this was a wonderful way to spend ti...  positive   \n3  Basically there's a family where a little boy ...  negative   \n4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n\n                                        clean_review  \n0  [one, reviewers, mentioned, watching, oz, epis...  \n1  [wonderful, little, production, filming, techn...  \n2  [thought, wonderful, way, spend, time, hot, su...  \n3  [basically, theres, family, little, boy, jake,...  \n4  [petter, matteis, love, time, money, visually,...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>clean_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>[wonderful, little, production, filming, techn...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>[basically, theres, family, little, boy, jake,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>[petter, matteis, love, time, money, visually,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'positive': 1, 'negative': 0}\n",
        "df['label'] = df['sentiment'].map(label_dict)\n",
        "df.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:15:12.269314Z",
          "iopub.execute_input": "2024-09-01T08:15:12.2702Z",
          "iopub.status.idle": "2024-09-01T08:15:12.300306Z",
          "shell.execute_reply.started": "2024-09-01T08:15:12.270155Z",
          "shell.execute_reply": "2024-09-01T08:15:12.299156Z"
        },
        "trusted": true,
        "id": "Aw8kwx6OtrpP",
        "outputId": "f327e74a-4fc1-4d39-9d52-98e35f542044"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              review sentiment  \\\n0  One of the other reviewers has mentioned that ...  positive   \n1  A wonderful little production. <br /><br />The...  positive   \n2  I thought this was a wonderful way to spend ti...  positive   \n3  Basically there's a family where a little boy ...  negative   \n4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n\n                                        clean_review  label  \n0  [one, reviewers, mentioned, watching, oz, epis...      1  \n1  [wonderful, little, production, filming, techn...      1  \n2  [thought, wonderful, way, spend, time, hot, su...      1  \n3  [basically, theres, family, little, boy, jake,...      0  \n4  [petter, matteis, love, time, money, visually,...      1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>clean_review</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>[wonderful, little, production, filming, techn...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>[basically, theres, family, little, boy, jake,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>[petter, matteis, love, time, money, visually,...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['clean_review']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:15:26.357444Z",
          "iopub.execute_input": "2024-09-01T08:15:26.357813Z",
          "iopub.status.idle": "2024-09-01T08:15:26.373182Z",
          "shell.execute_reply.started": "2024-09-01T08:15:26.357781Z",
          "shell.execute_reply": "2024-09-01T08:15:26.372349Z"
        },
        "trusted": true,
        "id": "pSkgcorPtrpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Build vocabulary\n",
        "all_words = [word for tokens in X_train for word in tokens]\n",
        "word_counts = Counter(all_words)\n",
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(f\"Vocab size: {vocab_size}\")\n",
        "\n",
        "# Word to index mapping\n",
        "word_to_idx = {word: idx+2 for idx, word in enumerate(vocab)}\n",
        "word_to_idx[\"<PAD>\"] = 0\n",
        "word_to_idx[\"<UNK>\"] = 1\n",
        "\n",
        "# Index to word mapping\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:15:58.340674Z",
          "iopub.execute_input": "2024-09-01T08:15:58.341515Z",
          "iopub.status.idle": "2024-09-01T08:15:59.503718Z",
          "shell.execute_reply.started": "2024-09-01T08:15:58.341474Z",
          "shell.execute_reply": "2024-09-01T08:15:59.502742Z"
        },
        "trusted": true,
        "id": "XLJHl4IktrpQ",
        "outputId": "8405f145-81ce-414a-e085-87faa83f33cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Vocab size: 186211\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text(text):\n",
        "    return [word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in text]\n",
        "\n",
        "# Encode training and testing data\n",
        "X_train_enc = X_train.apply(encode_text)\n",
        "X_test_enc = X_test.apply(encode_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:16:42.717542Z",
          "iopub.execute_input": "2024-09-01T08:16:42.718284Z",
          "iopub.status.idle": "2024-09-01T08:16:44.715492Z",
          "shell.execute_reply.started": "2024-09-01T08:16:42.718243Z",
          "shell.execute_reply": "2024-09-01T08:16:44.714515Z"
        },
        "trusted": true,
        "id": "cnHVz1QItrpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:16:59.202124Z",
          "iopub.execute_input": "2024-09-01T08:16:59.202514Z",
          "iopub.status.idle": "2024-09-01T08:16:59.207164Z",
          "shell.execute_reply.started": "2024-09-01T08:16:59.202479Z",
          "shell.execute_reply": "2024-09-01T08:16:59.206094Z"
        },
        "trusted": true,
        "id": "IX0di_k8trpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sequences, max_len):\n",
        "    sequences = [torch.tensor(seq[:max_len]) for seq in sequences]\n",
        "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=word_to_idx[\"<PAD>\"])\n",
        "    return sequences_padded\n",
        "\n",
        "max_len = 200  # Define max length\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_enc, max_len)\n",
        "X_test_padded = pad_sequences(X_test_enc, max_len)\n",
        "\n",
        "# Convert labels to tensors\n",
        "y_train_tensor = torch.tensor(y_train.values)\n",
        "y_test_tensor = torch.tensor(y_test.values)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:17:16.796492Z",
          "iopub.execute_input": "2024-09-01T08:17:16.796882Z",
          "iopub.status.idle": "2024-09-01T08:17:19.596035Z",
          "shell.execute_reply.started": "2024-09-01T08:17:16.796845Z",
          "shell.execute_reply": "2024-09-01T08:17:19.595006Z"
        },
        "trusted": true,
        "id": "J_SbWzLatrpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train_padded, y_train_tensor)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test_padded, y_test_tensor)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:18:02.264002Z",
          "iopub.execute_input": "2024-09-01T08:18:02.26472Z",
          "iopub.status.idle": "2024-09-01T08:18:02.27131Z",
          "shell.execute_reply.started": "2024-09-01T08:18:02.264677Z",
          "shell.execute_reply": "2024-09-01T08:18:02.270376Z"
        },
        "trusted": true,
        "id": "tLJjISbUtrpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "glove_path = '/kaggle/input/glove-6b/glove.6B.100d.txt'\n",
        "\n",
        "# Load GloVe embeddings\n",
        "embeddings_index = {}\n",
        "with open(glove_path, encoding='utf8') as f:\n",
        "    for line in tqdm(f, desc=\"Loading GloVe\"):\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        coeffs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coeffs\n",
        "\n",
        "print(f\"Loaded {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:18:52.040972Z",
          "iopub.execute_input": "2024-09-01T08:18:52.041346Z",
          "iopub.status.idle": "2024-09-01T08:19:04.691713Z",
          "shell.execute_reply.started": "2024-09-01T08:18:52.041314Z",
          "shell.execute_reply": "2024-09-01T08:19:04.690845Z"
        },
        "trusted": true,
        "id": "Wb2ZImgStrpR",
        "outputId": "b4db5ce9-17fb-46f3-a0f6-732ae89c625a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Loading GloVe: 400000it [00:12, 31667.74it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Loaded 400000 word vectors.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size + 2, embedding_dim))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:19:27.755411Z",
          "iopub.execute_input": "2024-09-01T08:19:27.755813Z",
          "iopub.status.idle": "2024-09-01T08:19:27.761198Z",
          "shell.execute_reply.started": "2024-09-01T08:19:27.755772Z",
          "shell.execute_reply": "2024-09-01T08:19:27.760148Z"
        },
        "trusted": true,
        "id": "v-F5rizotrpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, idx in word_to_idx.items():\n",
        "    if word in embeddings_index:\n",
        "        embedding_matrix[idx] = embeddings_index[word]\n",
        "    else:\n",
        "        # Initialize random embedding for words not in GloVe\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:19:36.487411Z",
          "iopub.execute_input": "2024-09-01T08:19:36.488149Z",
          "iopub.status.idle": "2024-09-01T08:19:37.47183Z",
          "shell.execute_reply.started": "2024-09-01T08:19:36.488106Z",
          "shell.execute_reply": "2024-09-01T08:19:37.470743Z"
        },
        "trusted": true,
        "id": "howLuUvVtrpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensor\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:19:44.475518Z",
          "iopub.execute_input": "2024-09-01T08:19:44.476066Z",
          "iopub.status.idle": "2024-09-01T08:19:44.519979Z",
          "shell.execute_reply.started": "2024-09-01T08:19:44.476014Z",
          "shell.execute_reply": "2024-09-01T08:19:44.519016Z"
        },
        "trusted": true,
        "id": "eWCJfOhTtrpS",
        "outputId": "ab394866-0058-4adc-e77e-802890e2fe54"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Embedding matrix shape: torch.Size([186213, 100])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x)\n",
        "        rnn_out, hidden = self.rnn(embeds)\n",
        "        out = self.dropout(hidden[-1])\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:20:03.202387Z",
          "iopub.execute_input": "2024-09-01T08:20:03.203257Z",
          "iopub.status.idle": "2024-09-01T08:20:03.210669Z",
          "shell.execute_reply.started": "2024-09-01T08:20:03.203215Z",
          "shell.execute_reply": "2024-09-01T08:20:03.209738Z"
        },
        "trusted": true,
        "id": "1UXCfoJLtrpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, (hidden, cell) = self.lstm(embeds)\n",
        "        out = self.dropout(hidden[-1])\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:20:12.684968Z",
          "iopub.execute_input": "2024-09-01T08:20:12.685585Z",
          "iopub.status.idle": "2024-09-01T08:20:12.692944Z",
          "shell.execute_reply.started": "2024-09-01T08:20:12.685546Z",
          "shell.execute_reply": "2024-09-01T08:20:12.691879Z"
        },
        "trusted": true,
        "id": "_FWCzD8atrpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, epochs, device):\n",
        "    model.to(device)\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "\n",
        "        for texts, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(texts)\n",
        "            loss = criterion(predictions.squeeze(), labels.float())\n",
        "            preds = torch.round(torch.sigmoid(predictions.squeeze()))\n",
        "            acc = (preds == labels).float().mean()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "        valid_loss, valid_acc = evaluate_model(model, valid_loader, criterion, device)\n",
        "\n",
        "        print(f'\\nEpoch {epoch+1}/{epochs}')\n",
        "        print(f'Train Loss: {epoch_loss/len(train_loader):.3f} | Train Acc: {epoch_acc/len(train_loader):.3f}')\n",
        "        print(f'Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.3f}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:21:22.649898Z",
          "iopub.execute_input": "2024-09-01T08:21:22.650334Z",
          "iopub.status.idle": "2024-09-01T08:21:22.65992Z",
          "shell.execute_reply.started": "2024-09-01T08:21:22.650297Z",
          "shell.execute_reply": "2024-09-01T08:21:22.658975Z"
        },
        "trusted": true,
        "id": "glbbwZV6trpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in data_loader:\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            predictions = model(texts)\n",
        "            loss = criterion(predictions.squeeze(), labels.float())\n",
        "            preds = torch.round(torch.sigmoid(predictions.squeeze()))\n",
        "            acc = (preds == labels).float().mean()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:22:54.157137Z",
          "iopub.execute_input": "2024-09-01T08:22:54.158073Z",
          "iopub.status.idle": "2024-09-01T08:22:54.165509Z",
          "shell.execute_reply.started": "2024-09-01T08:22:54.158032Z",
          "shell.execute_reply": "2024-09-01T08:22:54.164431Z"
        },
        "trusted": true,
        "id": "yj-BCWZJtrpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "n_layers = 2\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize model, criterion and optimizer\n",
        "rnn_model = RNNClassifier(embedding_matrix, hidden_dim, output_dim, n_layers)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "trained_rnn_model = train_model(rnn_model, train_loader, test_loader, criterion, optimizer, epochs, device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:23:08.489828Z",
          "iopub.execute_input": "2024-09-01T08:23:08.490773Z",
          "iopub.status.idle": "2024-09-01T08:23:32.599326Z",
          "shell.execute_reply.started": "2024-09-01T08:23:08.490732Z",
          "shell.execute_reply": "2024-09-01T08:23:32.598372Z"
        },
        "trusted": true,
        "id": "C2yV5X4BtrpS",
        "outputId": "2c80ec53-d6df-4c07-e225-eea8020b66c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Epoch 1/5: 100%|██████████| 625/625 [00:04<00:00, 126.51it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/5\nTrain Loss: 0.698 | Train Acc: 0.503\nVal. Loss: 0.693 |  Val. Acc: 0.505\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/5: 100%|██████████| 625/625 [00:04<00:00, 148.66it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 2/5\nTrain Loss: 0.694 | Train Acc: 0.509\nVal. Loss: 0.693 |  Val. Acc: 0.504\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/5: 100%|██████████| 625/625 [00:04<00:00, 149.11it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 3/5\nTrain Loss: 0.691 | Train Acc: 0.517\nVal. Loss: 0.695 |  Val. Acc: 0.502\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/5: 100%|██████████| 625/625 [00:04<00:00, 149.13it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 4/5\nTrain Loss: 0.694 | Train Acc: 0.514\nVal. Loss: 0.692 |  Val. Acc: 0.522\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/5: 100%|██████████| 625/625 [00:04<00:00, 149.56it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 5/5\nTrain Loss: 0.694 | Train Acc: 0.515\nVal. Loss: 0.693 |  Val. Acc: 0.518\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, criterion and optimizer\n",
        "lstm_model = LSTMClassifier(embedding_matrix, hidden_dim, output_dim, n_layers)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "trained_lstm_model = train_model(lstm_model, train_loader, test_loader, criterion, optimizer, epochs, device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:24:09.317218Z",
          "iopub.execute_input": "2024-09-01T08:24:09.317855Z",
          "iopub.status.idle": "2024-09-01T08:25:07.290003Z",
          "shell.execute_reply.started": "2024-09-01T08:24:09.317808Z",
          "shell.execute_reply": "2024-09-01T08:25:07.289032Z"
        },
        "trusted": true,
        "id": "BAZUrdQ2trpT",
        "outputId": "9e93559c-32e0-4a6c-8877-9dde1f07094a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Epoch 1/5: 100%|██████████| 625/625 [00:10<00:00, 58.30it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/5\nTrain Loss: 0.693 | Train Acc: 0.506\nVal. Loss: 0.693 |  Val. Acc: 0.506\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/5: 100%|██████████| 625/625 [00:10<00:00, 58.34it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 2/5\nTrain Loss: 0.685 | Train Acc: 0.529\nVal. Loss: 0.687 |  Val. Acc: 0.529\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/5: 100%|██████████| 625/625 [00:10<00:00, 58.48it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 3/5\nTrain Loss: 0.603 | Train Acc: 0.655\nVal. Loss: 0.544 |  Val. Acc: 0.731\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/5: 100%|██████████| 625/625 [00:10<00:00, 58.48it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 4/5\nTrain Loss: 0.402 | Train Acc: 0.839\nVal. Loss: 0.441 |  Val. Acc: 0.788\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/5: 100%|██████████| 625/625 [00:10<00:00, 58.57it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 5/5\nTrain Loss: 0.258 | Train Acc: 0.898\nVal. Loss: 0.441 |  Val. Acc: 0.819\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in data_loader:\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            predictions = model(texts)\n",
        "            preds = torch.round(torch.sigmoid(predictions.squeeze()))\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=['Negative', 'Positive'])\n",
        "\n",
        "    print(f'Accuracy: {acc:.3f}')\n",
        "    print(report)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:25:10.538504Z",
          "iopub.execute_input": "2024-09-01T08:25:10.539306Z",
          "iopub.status.idle": "2024-09-01T08:25:10.546527Z",
          "shell.execute_reply.started": "2024-09-01T08:25:10.539263Z",
          "shell.execute_reply": "2024-09-01T08:25:10.545489Z"
        },
        "trusted": true,
        "id": "aUBxXqmgtrpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RNN Model Evaluation:\")\n",
        "test_model(trained_rnn_model, test_loader, device)\n",
        "\n",
        "print(\"LSTM Model Evaluation:\")\n",
        "test_model(trained_lstm_model, test_loader, device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:25:48.910765Z",
          "iopub.execute_input": "2024-09-01T08:25:48.911557Z",
          "iopub.status.idle": "2024-09-01T08:25:50.136639Z",
          "shell.execute_reply.started": "2024-09-01T08:25:48.911517Z",
          "shell.execute_reply": "2024-09-01T08:25:50.135584Z"
        },
        "trusted": true,
        "id": "U2iWB46atrpT",
        "outputId": "a11f9ab4-198a-46fc-88d7-4e83a87d70d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "RNN Model Evaluation:\nAccuracy: 0.518\n              precision    recall  f1-score   support\n\n    Negative       0.51      0.65      0.57      4961\n    Positive       0.53      0.39      0.45      5039\n\n    accuracy                           0.52     10000\n   macro avg       0.52      0.52      0.51     10000\nweighted avg       0.52      0.52      0.51     10000\n\nLSTM Model Evaluation:\nAccuracy: 0.819\n              precision    recall  f1-score   support\n\n    Negative       0.96      0.66      0.78      4961\n    Positive       0.74      0.97      0.84      5039\n\n    accuracy                           0.82     10000\n   macro avg       0.85      0.82      0.81     10000\nweighted avg       0.85      0.82      0.81     10000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifierOnTheFly(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n",
        "        super(RNNClassifierOnTheFly, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x)\n",
        "        rnn_out, hidden = self.rnn(embeds)\n",
        "        out = self.dropout(hidden[-1])\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:27:45.133225Z",
          "iopub.execute_input": "2024-09-01T08:27:45.133652Z",
          "iopub.status.idle": "2024-09-01T08:27:45.141689Z",
          "shell.execute_reply.started": "2024-09-01T08:27:45.133614Z",
          "shell.execute_reply": "2024-09-01T08:27:45.140468Z"
        },
        "trusted": true,
        "id": "tZufozA2trpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifierOnTheFly(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n",
        "        super(LSTMClassifierOnTheFly, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, (hidden, cell) = self.lstm(embeds)\n",
        "        out = self.dropout(hidden[-1])\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:27:52.696604Z",
          "iopub.execute_input": "2024-09-01T08:27:52.697499Z",
          "iopub.status.idle": "2024-09-01T08:27:52.704784Z",
          "shell.execute_reply.started": "2024-09-01T08:27:52.697458Z",
          "shell.execute_reply": "2024-09-01T08:27:52.703739Z"
        },
        "trusted": true,
        "id": "Gw_PrgRftrpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "embedding_dim = 100  # Same as GloVe\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "n_layers = 2\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "rnn_model_otf = RNNClassifierOnTheFly(len(word_to_idx), embedding_dim, hidden_dim, output_dim, n_layers)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(rnn_model_otf.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "trained_rnn_model_otf = train_model(rnn_model_otf, train_loader, test_loader, criterion, optimizer, epochs, device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:28:04.6458Z",
          "iopub.execute_input": "2024-09-01T08:28:04.646713Z",
          "iopub.status.idle": "2024-09-01T08:28:28.567297Z",
          "shell.execute_reply.started": "2024-09-01T08:28:04.646669Z",
          "shell.execute_reply": "2024-09-01T08:28:28.566225Z"
        },
        "trusted": true,
        "id": "dddO927AtrpT",
        "outputId": "fc86fddf-8e1f-455f-da3d-cc811f5ee1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Epoch 1/5: 100%|██████████| 625/625 [00:04<00:00, 141.57it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/5\nTrain Loss: 0.699 | Train Acc: 0.505\nVal. Loss: 0.693 |  Val. Acc: 0.501\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/5: 100%|██████████| 625/625 [00:04<00:00, 139.08it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 2/5\nTrain Loss: 0.694 | Train Acc: 0.508\nVal. Loss: 0.694 |  Val. Acc: 0.501\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/5: 100%|██████████| 625/625 [00:04<00:00, 139.67it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 3/5\nTrain Loss: 0.693 | Train Acc: 0.514\nVal. Loss: 0.696 |  Val. Acc: 0.502\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/5: 100%|██████████| 625/625 [00:04<00:00, 139.08it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 4/5\nTrain Loss: 0.694 | Train Acc: 0.507\nVal. Loss: 0.694 |  Val. Acc: 0.498\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/5: 100%|██████████| 625/625 [00:04<00:00, 140.15it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 5/5\nTrain Loss: 0.696 | Train Acc: 0.500\nVal. Loss: 0.693 |  Val. Acc: 0.504\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, criterion, and optimizer\n",
        "lstm_model_otf = LSTMClassifierOnTheFly(len(word_to_idx), embedding_dim, hidden_dim, output_dim, n_layers)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(lstm_model_otf.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "trained_lstm_model_otf = train_model(lstm_model_otf, train_loader, test_loader, criterion, optimizer, epochs, device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:28:41.924074Z",
          "iopub.execute_input": "2024-09-01T08:28:41.924471Z",
          "iopub.status.idle": "2024-09-01T08:29:40.384315Z",
          "shell.execute_reply.started": "2024-09-01T08:28:41.924432Z",
          "shell.execute_reply": "2024-09-01T08:29:40.383311Z"
        },
        "trusted": true,
        "id": "gMmlAECItrpT",
        "outputId": "999e927e-ace3-4f7c-f4e8-7d6a1e34c749"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Epoch 1/5: 100%|██████████| 625/625 [00:10<00:00, 58.33it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/5\nTrain Loss: 0.693 | Train Acc: 0.504\nVal. Loss: 0.688 |  Val. Acc: 0.518\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/5: 100%|██████████| 625/625 [00:10<00:00, 58.01it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 2/5\nTrain Loss: 0.680 | Train Acc: 0.553\nVal. Loss: 0.686 |  Val. Acc: 0.528\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/5: 100%|██████████| 625/625 [00:10<00:00, 58.06it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 3/5\nTrain Loss: 0.667 | Train Acc: 0.571\nVal. Loss: 0.681 |  Val. Acc: 0.548\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/5: 100%|██████████| 625/625 [00:10<00:00, 58.25it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 4/5\nTrain Loss: 0.561 | Train Acc: 0.724\nVal. Loss: 0.508 |  Val. Acc: 0.780\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/5: 100%|██████████| 625/625 [00:10<00:00, 58.14it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 5/5\nTrain Loss: 0.436 | Train Acc: 0.808\nVal. Loss: 0.436 |  Val. Acc: 0.818\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RNN Model with On-the-Fly Embeddings Evaluation:\")\n",
        "test_model(trained_rnn_model_otf, test_loader, device)\n",
        "\n",
        "print(\"LSTM Model with On-the-Fly Embeddings Evaluation:\")\n",
        "test_model(trained_lstm_model_otf, test_loader, device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-01T08:29:44.609668Z",
          "iopub.execute_input": "2024-09-01T08:29:44.610449Z",
          "iopub.status.idle": "2024-09-01T08:29:45.837456Z",
          "shell.execute_reply.started": "2024-09-01T08:29:44.610405Z",
          "shell.execute_reply": "2024-09-01T08:29:45.836339Z"
        },
        "trusted": true,
        "id": "DIx1SaA7trpU",
        "outputId": "ece9f6e6-8d1f-484a-98f2-564e3dd5717b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "RNN Model with On-the-Fly Embeddings Evaluation:\nAccuracy: 0.504\n              precision    recall  f1-score   support\n\n    Negative       0.48      0.01      0.02      4961\n    Positive       0.50      0.99      0.67      5039\n\n    accuracy                           0.50     10000\n   macro avg       0.49      0.50      0.34     10000\nweighted avg       0.49      0.50      0.35     10000\n\nLSTM Model with On-the-Fly Embeddings Evaluation:\nAccuracy: 0.818\n              precision    recall  f1-score   support\n\n    Negative       0.81      0.83      0.82      4961\n    Positive       0.83      0.80      0.82      5039\n\n    accuracy                           0.82     10000\n   macro avg       0.82      0.82      0.82     10000\nweighted avg       0.82      0.82      0.82     10000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8gNpNEiLtrpU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}